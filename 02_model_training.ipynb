{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair LoRA Model Training\n",
    "\n",
    "é€™å€‹ notebook ä½¿ç”¨å…¬å¹³æ€§å¢žå¼·çš„ LoRA å¾®èª¿æ–¹æ³• (Base: BAAI/bge-large-en-v1.5) ä¾†é€²è¡Œå±¥æ­·èˆ‡è·ä½æè¿°é…å°ï¼ŒåŒæ™‚ç›¡é‡é™ä½Žä¸åŒæ•™è‚²èƒŒæ™¯ç¾¤çµ„ä¹‹é–“çš„é æ¸¬å·®ç•°ã€‚\n",
    "\n",
    "è³‡æ–™ä¾†æºï¼šç¾åœ¨å·²æ›´æ–°ç‚ºé‡æ–°åˆ†å‰²å¾Œçš„è³‡æ–™é›† `processed_resume_dataset_resplit`ï¼Œç¢ºä¿åœ¨ train/val/test ä¸­éƒ½å­˜åœ¨æ­£ä¾‹ï¼Œé¿å…å…¬å¹³æ€§æŒ‡æ¨™é€€åŒ–ã€‚\n",
    "\n",
    "## ç›®æ¨™\n",
    "\n",
    "- ä¸»ä»»å‹™ï¼šé æ¸¬å±¥æ­·èˆ‡è·ä½æ˜¯å¦åŒ¹é… (Fit / No Fit)\n",
    "- æ•æ„Ÿå±¬æ€§ï¼š`is_top_school`, `school_category`\n",
    "- å…¬å¹³æ€§ç­–ç•¥ï¼š\n",
    "  - æ•æ„Ÿå±¬æ€§å±è”½ï¼ˆæ–‡å­—æ›¿æ›ç‚ºä¸­æ€§æ¨™è¨˜ï¼‰\n",
    "  - LoRA å¾®èª¿ (r=8, alpha=16, target_modules=['query','key','value'])\n",
    "  - å°æŠ—å¼åŽ»å (Adversarial Debiasing)\n",
    "  - å¤šä»»å‹™å­¸ç¿’ (è¼”åŠ©é æ¸¬ school_category ä»¥æ­£å‰‡åŒ–è¡¨ç¤º)\n",
    "  - åŠ æ¬Š/é‡æŠ½æ¨£æ¸›å°‘ç¾¤é«”ä¸å¹³è¡¡\n",
    "  - å…¬å¹³æ€§æŒ‡æ¨™ç›£æŽ§èˆ‡æ—©åœ (Demographic Parity / Equalized Odds / Equal Opportunity)\n",
    "\n",
    "## æµç¨‹\n",
    "1. ç’°å¢ƒèˆ‡åƒæ•¸è¨­ç½®\n",
    "2. æ•¸æ“šåŠ è¼‰èˆ‡æ•æ„Ÿå±¬æ€§å±è”½ï¼ˆä½¿ç”¨æ–°çš„é‡æ–°åˆ†å‰²è³‡æ–™é›†ï¼‰\n",
    "3. å»ºç«‹æ¨¡åž‹èˆ‡ LoRA é…ç½®\n",
    "4. è¨“ç·´è¿´åœˆï¼ˆåŒ…å«å°æŠ— + å…¬å¹³æ€§æå¤±ï¼‰\n",
    "5. è©•ä¼°èˆ‡å…¬å¹³æ€§æŒ‡æ¨™è¼¸å‡ºï¼ˆæ”¯æ´å¾ŒçºŒé–¾å€¼å¾®èª¿ï¼‰\n",
    "6. ä¿å­˜æœ€ä½³æ¨¡åž‹èˆ‡è¨“ç·´è¨˜éŒ„\n",
    "\n",
    "åŸ·è¡Œ Cells 1â†’N å®Œæˆæ•´é«”è¨“ç·´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Dataset path: /Users/edwardhuang/Documents/GitHub/bge-lora-fairness-finetuning/data/processed/processed_resume_dataset_resplit\n",
      "GroupBatchSampler enabled: False\n",
      "Balanced validation enabled: True\n",
      "Fairness regularizer lambda: 0.05\n",
      "Temperature calibration: True\n",
      "AUC metrics enabled: True\n"
     ]
    }
   ],
   "source": [
    "# Imports & configuration (updated for new sampler/balanced validation)\n",
    "import sys, json\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path('.').resolve()\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from fair_lora_config import (\n",
    "    BASE_MODEL, DATASET_PATH, DEVICE, LEARNING_RATE, MAX_GRAD_NORM,\n",
    "    ADVERSARIAL_LAMBDA, FAIRNESS_LAMBDA, MULTITASK_LAMBDA,\n",
    "    USE_GROUP_BATCH_SAMPLER, USE_REWEIGHTING, CREATE_BALANCED_VAL,\n",
    "    FAIRNESS_REG_LAMBDA, WINDOW_SELECTION_START, WINDOW_SELECTION_END,\n",
    "    WINDOW_FAIRNESS_THRESHOLD, TEMPERATURE_CALIBRATION, AUC_ENABLED\n",
    ")\n",
    "\n",
    "from src.fair_data_loader import create_data_loaders\n",
    "from src.fair_lora_model import FairLoRAModel\n",
    "from src.fair_trainer import FairTrainer\n",
    "import torch\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"GroupBatchSampler enabled: {USE_GROUP_BATCH_SAMPLER}\")\n",
    "print(f\"Balanced validation enabled: {CREATE_BALANCED_VAL}\")\n",
    "print(f\"Fairness regularizer lambda: {FAIRNESS_REG_LAMBDA}\")\n",
    "print(f\"Temperature calibration: {TEMPERATURE_CALIBRATION}\")\n",
    "print(f\"AUC metrics enabled: {AUC_ENABLED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip: use the enhanced create_data_loaders call in the next cell (returns 5 values).\n"
     ]
    }
   ],
   "source": [
    "# (Deprecated) Initial simple loader call replaced by enhanced call in next cell.\n",
    "# Keeping this cell as a placeholder to avoid unpack errors.\n",
    "print(\"Skip: use the enhanced create_data_loaders call in the next cell (returns 5 values).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ Loading dataset from /Users/edwardhuang/Documents/GitHub/bge-lora-fairness-finetuning/data/processed/processed_resume_dataset_resplit...\n",
      "   Train: 5,472 samples\n",
      "   Val:   685 samples\n",
      "   Test:  1,087 samples\n",
      "\n",
      "ðŸ“Š School Distribution:\n",
      "\n",
      "   Train:\n",
      "     no_school_mentioned...........   884 (16.15%)\n",
      "     non_top_school................  4365 (79.77%)\n",
      "     top_school....................   223 ( 4.08%)\n",
      "\n",
      "   Val:\n",
      "     non_top_school................   547 (79.85%)\n",
      "     no_school_mentioned...........   111 (16.20%)\n",
      "     top_school....................    27 ( 3.94%)\n",
      "\n",
      "   Test:\n",
      "     non_top_school................   867 (79.76%)\n",
      "     no_school_mentioned...........   176 (16.19%)\n",
      "     top_school....................    44 ( 4.05%)\n",
      "\n",
      "ðŸ”¤ Loading tokenizer: BAAI/bge-large-en-v1.5\n",
      "\n",
      "âš–ï¸  Using weighted sampling for fairness...\n",
      "\n",
      "ðŸ§ª Balanced Val created (joint groups): 81 samples; per-group ~27\n",
      "\n",
      "âœ… Data loaders created successfully!\n",
      "   Train batches: 684\n",
      "   Val batches:   86\n",
      "   Test batches:  136\n",
      "   Balanced Val batches: 11\n",
      "Train batches: 684 | Val batches: 86 | Test batches: 136\n",
      "Balanced Val loader: present\n",
      "\n",
      "âš–ï¸  Using weighted sampling for fairness...\n",
      "\n",
      "ðŸ§ª Balanced Val created (joint groups): 81 samples; per-group ~27\n",
      "\n",
      "âœ… Data loaders created successfully!\n",
      "   Train batches: 684\n",
      "   Val batches:   86\n",
      "   Test batches:  136\n",
      "   Balanced Val batches: 11\n",
      "Train batches: 684 | Val batches: 86 | Test batches: 136\n",
      "Balanced Val loader: present\n"
     ]
    }
   ],
   "source": [
    "# Load data with new sampler + balanced validation loader\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    tokenizer,\n",
    "    balanced_val_loader\n",
    ") = create_data_loaders(\n",
    "    dataset_path=str(DATASET_PATH),\n",
    "    batch_size=8,  # reduced from 16 to 8 to mitigate MPS OOM\n",
    "    max_seq_length=256,  # limit sequence length to 256 (try 384 if quality drops)\n",
    "    use_reweighting=USE_REWEIGHTING and not USE_GROUP_BATCH_SAMPLER,  # avoid double fairness intervention\n",
    "    use_group_batch_sampler=USE_GROUP_BATCH_SAMPLER,\n",
    "    create_balanced_val=CREATE_BALANCED_VAL,\n",
    "    num_workers=2 if DEVICE.type == 'mps' else 4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)} | Test batches: {len(test_loader)}\")\n",
    "print(f\"Balanced Val loader: {'present' if balanced_val_loader is not None else 'none'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Loading base model: BAAI/bge-large-en-v1.5\n",
      "ðŸ”§ Applying LoRA (expanded targets, r=16, alpha=32)...\n",
      "   â€¢ LoRA target modules detected: ['dense', 'key', 'query', 'value']\n",
      "     (modules not present are ignored silently by PEFT)\n",
      "ðŸ”’ Frozen encoder base weights except attention in last 4 layers; LoRA adapters remain trainable.\n",
      "ðŸ“Š Trainable params -> LoRA: 7,110,656 | Base last4(attn): 16,801,792 | Total: 23,912,448\n",
      "trainable params: 23,912,448 || all params: 342,252,544 || trainable%: 6.9868\n",
      "ðŸ”§ Adding adversarial discriminator...\n",
      "ðŸ”§ Adding attribute classifier for multi-task learning...\n",
      "ðŸ”§ Applying LoRA (expanded targets, r=16, alpha=32)...\n",
      "   â€¢ LoRA target modules detected: ['dense', 'key', 'query', 'value']\n",
      "     (modules not present are ignored silently by PEFT)\n",
      "ðŸ”’ Frozen encoder base weights except attention in last 4 layers; LoRA adapters remain trainable.\n",
      "ðŸ“Š Trainable params -> LoRA: 7,110,656 | Base last4(attn): 16,801,792 | Total: 23,912,448\n",
      "trainable params: 23,912,448 || all params: 342,252,544 || trainable%: 6.9868\n",
      "ðŸ”§ Adding adversarial discriminator...\n",
      "ðŸ”§ Adding attribute classifier for multi-task learning...\n",
      "Gradient checkpointing enabled.\n",
      "Gradient checkpointing enabled.\n"
     ]
    }
   ],
   "source": [
    "# Build model with optional gradient checkpointing for memory savings\n",
    "model = FairLoRAModel(\n",
    "    base_model_name=BASE_MODEL,\n",
    "    use_lora=True,\n",
    "    use_adversarial=True,\n",
    "    use_multitask=True,\n",
    "    num_labels=2\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Enable gradient checkpointing if available (helps reduce memory footprint)\n",
    "try:\n",
    "    base_attr = None\n",
    "    for attr_name in ['base_model','model']:\n",
    "        if hasattr(model, attr_name):\n",
    "            candidate = getattr(model, attr_name)\n",
    "            if hasattr(candidate, 'gradient_checkpointing_enable'):\n",
    "                candidate.gradient_checkpointing_enable()\n",
    "                base_attr = candidate\n",
    "                break\n",
    "    if base_attr is not None:\n",
    "        print(\"Gradient checkpointing enabled.\")\n",
    "    else:\n",
    "        print(\"Gradient checkpointing method not found; skipped.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gradient checkpointing enabling failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready.\n"
     ]
    }
   ],
   "source": [
    "# Build trainer with balanced val and fairness reg + temperature/AUC toggles\n",
    "trainer = FairTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    balanced_val_loader=balanced_val_loader,\n",
    "    device=str(DEVICE),\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    adversarial_lambda=ADVERSARIAL_LAMBDA,\n",
    "    fairness_lambda=FAIRNESS_LAMBDA,\n",
    "    multitask_lambda=MULTITASK_LAMBDA,\n",
    "    fairness_reg_lambda=FAIRNESS_REG_LAMBDA,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    "    temperature_calibration=TEMPERATURE_CALIBRATION,\n",
    "    auc_enabled=AUC_ENABLED\n",
    ")\n",
    "print(\"Trainer ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 10260; Warmup steps (lambda ramp): 1026\n",
      "Using CosineAnnealingWarmRestarts with T_0=2 epochs (~1368 steps), T_mult=2.\n"
     ]
    }
   ],
   "source": [
    "# Scheduler + training loop params\n",
    "num_epochs = 15\n",
    "warmup_steps = int(0.1 * num_epochs * len(train_loader))  # 10% of total steps linear ramp\n",
    "patience = 5\n",
    "\n",
    "# CosineAnnealingWarmRestarts with restarts every ~2 epochs (measured in steps)\n",
    "import math\n",
    "steps_per_epoch = len(train_loader)\n",
    "t0_epochs = 2\n",
    "t0_steps = t0_epochs * steps_per_epoch  # since we step scheduler per batch\n",
    "eta_min = 0.0  # minimum LR at cosine trough; can raise slightly if needed\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    trainer.main_optimizer,\n",
    "    T_0=t0_steps,\n",
    "    T_mult=2,  # progressively longer cycles\n",
    "    eta_min=eta_min\n",
    ")\n",
    "print(f\"Total steps: {num_epochs * steps_per_epoch}; Warmup steps (lambda ramp): {warmup_steps}\")\n",
    "print(f\"Using CosineAnnealingWarmRestarts with T_0={t0_epochs} epochs (~{t0_steps} steps), T_mult=2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: mps\n",
      "Training batches: 684\n",
      "Validation batches: 86\n",
      "Adversarial debiasing: True\n",
      "Multi-task learning: True\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   0%|          | 0/684 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniconda/base/envs/ml-env/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml-env/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml-env/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml-env/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml-env/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml-env/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Epoch 1 [Train]:   5%|â–         | 33/684 [00:20<05:02,  2.15it/s, loss=0.8174, acc=44.32%, advÎ»=0.016, mtÎ»=0.006] "
     ]
    }
   ],
   "source": [
    "# Train with window selection and balanced fairness\n",
    "history = trainer.train(\n",
    "    num_epochs=num_epochs,\n",
    "    early_stopping_patience=patience,\n",
    "    scheduler=scheduler,\n",
    "    warmup_steps=warmup_steps,\n",
    "    adv_lambda_target=ADVERSARIAL_LAMBDA,\n",
    "    multitask_lambda_target=MULTITASK_LAMBDA,\n",
    "    fairness_lambda_target=FAIRNESS_LAMBDA,\n",
    "    window_selection_start=WINDOW_SELECTION_START,\n",
    "    window_selection_end=WINDOW_SELECTION_END,\n",
    "    window_fairness_threshold=WINDOW_FAIRNESS_THRESHOLD\n",
    ")\n",
    "print(\"Training complete. Best epoch:\", history.get('best_epoch'))\n",
    "print(\"Window-best epoch:\", history.get('window_best_epoch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved to models/fair_adversarial\n"
     ]
    }
   ],
   "source": [
    "# Inspect metrics CSV and fairness trajectories\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "metrics_csv = Path('models/fair_adversarial/epoch_metrics.csv')\n",
    "if metrics_csv.exists():\n",
    "    df_metrics = pd.read_csv(metrics_csv)\n",
    "    display(df_metrics.tail())\n",
    "    print(\"Fairness raw (last 5):\", df_metrics['fairness_score_raw'].tail().tolist())\n",
    "    print(\"Fairness balanced (last 5):\", df_metrics['fairness_score_balanced'].tail().tolist())\n",
    "else:\n",
    "    print(\"Metrics CSV not found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS matmul ok: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test with best and window-best checkpoints\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "best_epoch = history.get('best_epoch')\n",
    "window_best_epoch = history.get('window_best_epoch')\n",
    "\n",
    "print(f\"Best epoch: {best_epoch}; Window-best epoch: {window_best_epoch}\")\n",
    "\n",
    "# Load window-best if exists\n",
    "window_ckpt = Path('models/fair_adversarial/window_best_model.pt')\n",
    "if window_ckpt.exists():\n",
    "    trainer.load_checkpoint(window_ckpt)\n",
    "    print(\"Loaded window-best checkpoint for test evaluation.\")\n",
    "else:\n",
    "    print(\"Window-best checkpoint not found; using current trainer state.\")\n",
    "\n",
    "# Simple test evaluation using stored best threshold\n",
    "best_thr_list = history.get('best_thresholds', [])\n",
    "if best_thr_list and best_epoch:\n",
    "    thr_idx = max(0, best_epoch-1)\n",
    "    best_thr = best_thr_list[thr_idx]\n",
    "else:\n",
    "    best_thr = 0.5\n",
    "\n",
    "model.eval()\n",
    "labels_all = []\n",
    "probs_all = []\n",
    "sc_all = []\n",
    "ts_all = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        ids = batch['input_ids'].to(DEVICE)\n",
    "        mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['label'].to(DEVICE)\n",
    "        out = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        logits = out['logits']\n",
    "        probs = torch.softmax(logits, dim=1)[:,1]\n",
    "        labels_all.extend(labels.cpu().numpy())\n",
    "        probs_all.extend(probs.cpu().numpy())\n",
    "        sc_all.extend(batch['school_category'].cpu().numpy())\n",
    "        ts_all.extend(batch['is_top_school'].cpu().numpy())\n",
    "\n",
    "import numpy as np\n",
    "labels_np = np.array(labels_all)\n",
    "probs_np = np.array(probs_all)\n",
    "preds_np = (probs_np >= best_thr).astype(int)\n",
    "acc_test = (preds_np == labels_np).mean() if labels_np.size else 0.0\n",
    "print(f\"Test accuracy (threshold={best_thr:.3f}): {acc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>best_threshold</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>fairness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.691992</td>\n",
       "      <td>0.519708</td>\n",
       "      <td>0.006883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.690551</td>\n",
       "      <td>0.531387</td>\n",
       "      <td>0.006883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.687889</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.006883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.686120</td>\n",
       "      <td>0.563504</td>\n",
       "      <td>0.006883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.684175</td>\n",
       "      <td>0.556204</td>\n",
       "      <td>0.006883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  best_threshold  val_loss   val_acc  fairness_score\n",
       "0      1            0.05  0.691992  0.519708        0.006883\n",
       "1      2            0.05  0.690551  0.531387        0.006883\n",
       "2      3            0.05  0.687889  0.562044        0.006883\n",
       "3      4            0.05  0.686120  0.563504        0.006883\n",
       "4      5            0.05  0.684175  0.556204        0.006883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 5\n",
      "Best epoch threshold: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Summary of training history\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"History keys:\", list(history.keys()))\n",
    "print(\"Best epoch:\", history.get('best_epoch'))\n",
    "print(\"Window-best epoch:\", history.get('window_best_epoch'))\n",
    "print(\"Temperature trajectory:\", history.get('temperature')[-5:])\n",
    "print(\"Adv lambda final per epoch:\", history.get('adv_lambdas')[-5:])\n",
    "print(\"Multitask lambda final per epoch:\", history.get('multitask_lambdas')[-5:])\n",
    "print(\"Fairness reg gaps last 5:\", history.get('fairness_reg_gaps')[-5:])\n",
    "\n",
    "metrics_csv = Path('models/fair_adversarial/epoch_metrics.csv')\n",
    "if metrics_csv.exists():\n",
    "    df_metrics = pd.read_csv(metrics_csv)\n",
    "    print(\"\\nAUC last 5:\", df_metrics['val_auc'].tail().tolist())\n",
    "    print(\"PR-AUC last 5:\", df_metrics['val_pr_auc'].tail().tolist())\n",
    "else:\n",
    "    print(\"Metrics CSV not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
