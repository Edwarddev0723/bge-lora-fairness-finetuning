{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86195df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml-env/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bcfa87edd54b8cb102e2ba066e5ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/53.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05d5c7798f84d6782840505e5783497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv:   0%|          | 0.00/15.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89a5a93c4c24c4f93aba9803ca5356a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/6241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b32f6c2e18b4b40ad0fda31902fd69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1759 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Dataset sizes:\n",
      "  Train: 6,241\n",
      "  Test:  1,759\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "train_ds = load_dataset(\"cnamuangtoun/resume-job-description-fit\", split=\"train\")\n",
    "test_ds = load_dataset(\"cnamuangtoun/resume-job-description-fit\", split=\"test\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset sizes:\")\n",
    "print(f\"  Train: {len(train_ds):,}\")\n",
    "print(f\"  Test:  {len(test_ds):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96c19101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Extracting school classifications...\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Processing training set...\n",
      "  Processed 1,000 examples...\n",
      "  Processed 1,000 examples...\n",
      "  Processed 2,000 examples...\n",
      "  Processed 2,000 examples...\n",
      "  Processed 3,000 examples...\n",
      "  Processed 3,000 examples...\n",
      "  Processed 4,000 examples...\n",
      "  Processed 4,000 examples...\n",
      "  Processed 5,000 examples...\n",
      "  Processed 5,000 examples...\n",
      "  Processed 6,000 examples...\n",
      "  Processed 6,000 examples...\n",
      "\n",
      "ğŸ“ Processing test set...\n",
      "\n",
      "ğŸ“ Processing test set...\n",
      "  Processed 1,000 examples...\n",
      "  Processed 1,000 examples...\n",
      "\n",
      "âœ… Processing complete!\n",
      "============================================================\n",
      "\n",
      "âœ… Processing complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# ==================== å­¸æ ¡åˆ†é¡ (School Classification) ====================\n",
    "# Top schools åˆ—è¡¨ - ä½¿ç”¨æ›´ç²¾ç¢ºçš„ patterns\n",
    "TOP_SCHOOLS_PATTERNS = {\n",
    "    # Ivy League - å®Œæ•´åç¨± + å¸¸è¦‹ç¸®å¯«\n",
    "    'harvard': r'\\bharvard\\s+university\\b|\\bharvard\\b',\n",
    "    'yale': r'\\byale\\s+university\\b|\\byale\\b',\n",
    "    'princeton': r'\\bprinceton\\s+university\\b|\\bprinceton\\b',\n",
    "    'columbia': r'\\bcolumbia\\s+university\\b',\n",
    "    'upenn': r'\\buniversity\\s+of\\s+pennsylvania\\b|\\bupenn\\b|\\bu\\s+penn\\b',\n",
    "    'dartmouth': r'\\bdartmouth\\s+(college|university)\\b|\\bdartmouth\\b',\n",
    "    'brown': r'\\bbrown\\s+university\\b',\n",
    "    'cornell': r'\\bcornell\\s+university\\b|\\bcornell\\b',\n",
    "    \n",
    "    # Top US Universities\n",
    "    'stanford': r'\\bstanford\\s+university\\b|\\bstanford\\b',\n",
    "    'mit': r'\\bmassachusetts\\s+institute\\s+of\\s+technology\\b|\\b(?:mit)\\b(?!\\w)',\n",
    "    'caltech': r'\\bcalifornia\\s+institute\\s+of\\s+technology\\b|\\bcaltech\\b',\n",
    "    'uchicago': r'\\buniversity\\s+of\\s+chicago\\b|\\bchicago\\s+university\\b',\n",
    "    'duke': r'\\bduke\\s+university\\b|\\bduke\\b',\n",
    "    'northwestern': r'\\bnorthwestern\\s+university\\b|\\bnorthwestern\\b',\n",
    "    'johns_hopkins': r'\\bjohns\\s+hopkins\\s+university\\b|\\bjohns\\s+hopkins\\b',\n",
    "    'vanderbilt': r'\\bvanderbilt\\s+university\\b|\\bvanderbilt\\b',\n",
    "    'rice': r'\\brice\\s+university\\b',\n",
    "    'notre_dame': r'\\buniversity\\s+of\\s+notre\\s+dame\\b|\\bnotre\\s+dame\\b',\n",
    "    \n",
    "    # UC System\n",
    "    'berkeley': r'\\buc\\s+berkeley\\b|\\buniversity\\s+of\\s+california,?\\s+berkeley\\b|\\bberkeley\\s+university\\b',\n",
    "    'ucla': r'\\bucla\\b|\\buniversity\\s+of\\s+california,?\\s+los\\s+angeles\\b',\n",
    "    'ucsd': r'\\bucsd\\b|\\buniversity\\s+of\\s+california,?\\s+san\\s+diego\\b',\n",
    "    'usc': r'\\busc\\b(?=\\s+(?:university|school|college))|\\buniversity\\s+of\\s+southern\\s+california\\b',\n",
    "    \n",
    "    # Other Top US\n",
    "    'carnegie_mellon': r'\\bcarnegie\\s+mellon\\s+university\\b|\\bcarnegie\\s+mellon\\b|\\bcmu\\b',\n",
    "    'georgetown': r'\\bgeorgetown\\s+university\\b|\\bgeorgetown\\b',\n",
    "    'michigan': r'\\buniversity\\s+of\\s+michigan\\b|\\bumich\\b|\\bu\\s+michigan\\b',\n",
    "    'virginia': r'\\buniversity\\s+of\\s+virginia\\b|\\buva\\b',\n",
    "    \n",
    "    # UK Universities\n",
    "    'oxford': r'\\buniversity\\s+of\\s+oxford\\b|\\boxford\\s+university\\b',\n",
    "    'cambridge': r'\\buniversity\\s+of\\s+cambridge\\b|\\bcambridge\\s+university\\b',\n",
    "    'imperial': r'\\bimperial\\s+college\\s+london\\b|\\bimperial\\s+college\\b',\n",
    "    'lse': r'\\blondon\\s+school\\s+of\\s+economics\\b|\\blse\\b(?!\\w)',\n",
    "    'ucl': r'\\buniversity\\s+college\\s+london\\b|\\bucl\\b(?!\\w)',\n",
    "    'edinburgh': r'\\buniversity\\s+of\\s+edinburgh\\b|\\bedinburgh\\s+university\\b',\n",
    "    \n",
    "    # Canadian\n",
    "    'toronto': r'\\buniversity\\s+of\\s+toronto\\b|\\bu\\s+of\\s+t\\b',\n",
    "    'mcgill': r'\\bmcgill\\s+university\\b|\\bmcgill\\b',\n",
    "    'ubc': r'\\buniversity\\s+of\\s+british\\s+columbia\\b|\\bubc\\b(?!\\w)',\n",
    "    \n",
    "    # Asian\n",
    "    'national_taiwan_university': r'\\bnational\\s+taiwan\\s+university\\b',\n",
    "    'ntu_singapore': r'\\bnanyang\\s+technological\\s+university\\b|\\bntu\\s+singapore\\b',\n",
    "    'nus': r'\\bnational\\s+university\\s+of\\s+singapore\\b|\\bnus\\b(?!\\w)',\n",
    "    'peking': r'\\bpeking\\s+university\\b|\\bpku\\b',\n",
    "    'tsinghua': r'\\btsinghua\\s+university\\b',\n",
    "    'tokyo': r'\\buniversity\\s+of\\s+tokyo\\b|\\btokyo\\s+university\\b',\n",
    "    \n",
    "    # Australian\n",
    "    'melbourne': r'\\buniversity\\s+of\\s+melbourne\\b|\\bmelbourne\\s+university\\b',\n",
    "    'sydney': r'\\buniversity\\s+of\\s+sydney\\b|\\bsydney\\s+university\\b',\n",
    "    \n",
    "    # Public Ivies\n",
    "    'unc': r'\\buniversity\\s+of\\s+north\\s+carolina\\b|\\bunc\\s+chapel\\s+hill\\b|\\bunc\\b(?=\\s+(?:at|chapel))',\n",
    "}\n",
    "\n",
    "def classify_school(text):\n",
    "    \"\"\"\n",
    "    åˆ†é¡å­¸æ ¡ç‚º top school æˆ– non-top school (ä½¿ç”¨åš´æ ¼çš„ word boundary)\n",
    "    Returns: dict with school classification\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return {\n",
    "            'has_school': False,\n",
    "            'is_top_school': False,\n",
    "            'school_category': 'unknown',\n",
    "            'matched_schools': []\n",
    "        }\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # å°‹æ‰¾æåˆ°çš„ top schools (ä½¿ç”¨æ­£å‰‡è¡¨é”å¼ç²¾ç¢ºåŒ¹é…)\n",
    "    matched_schools = []\n",
    "    for school_name, pattern in TOP_SCHOOLS_PATTERNS.items():\n",
    "        if re.search(pattern, text_lower):\n",
    "            matched_schools.append(school_name)\n",
    "    \n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰ã€Œuniversityã€æˆ–ã€Œcollegeã€å­—æ¨£\n",
    "    has_school_mention = bool(re.search(r'\\b(university|college|institute|school)\\b', text_lower))\n",
    "    \n",
    "    if matched_schools:\n",
    "        school_category = 'top_school'\n",
    "        is_top_school = True\n",
    "    elif has_school_mention:\n",
    "        school_category = 'non_top_school'\n",
    "        is_top_school = False\n",
    "    else:\n",
    "        school_category = 'no_school_mentioned'\n",
    "        is_top_school = False\n",
    "    \n",
    "    return {\n",
    "        'has_school': has_school_mention or len(matched_schools) > 0,\n",
    "        'is_top_school': is_top_school,\n",
    "        'school_category': school_category,\n",
    "        'matched_schools': matched_schools\n",
    "    }\n",
    "\n",
    "\n",
    "# ==================== æ‡‰ç”¨åˆ°è³‡æ–™é›† ====================\n",
    "print(\"ğŸ” Extracting school classifications...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# è™•ç†è¨“ç·´é›†\n",
    "print(\"\\nğŸ“ Processing training set...\")\n",
    "train_school_stats = []\n",
    "\n",
    "for idx, example in enumerate(train_ds):\n",
    "    resume = example.get('resume_text', '')\n",
    "    \n",
    "    # å­¸æ ¡åˆ†é¡\n",
    "    school_info = classify_school(resume)\n",
    "    train_school_stats.append(school_info)\n",
    "    \n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"  Processed {idx + 1:,} examples...\")\n",
    "\n",
    "# è™•ç†æ¸¬è©¦é›†\n",
    "print(\"\\nğŸ“ Processing test set...\")\n",
    "test_school_stats = []\n",
    "\n",
    "for idx, example in enumerate(test_ds):\n",
    "    resume = example.get('resume_text', '')\n",
    "    \n",
    "    # å­¸æ ¡åˆ†é¡\n",
    "    school_info = classify_school(resume)\n",
    "    test_school_stats.append(school_info)\n",
    "    \n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"  Processed {idx + 1:,} examples...\")\n",
    "\n",
    "print(\"\\nâœ… Processing complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b32c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š SCHOOL CLASSIFICATION STATISTICS\n",
      "============================================================\n",
      "\n",
      "ğŸ“š Training Set (n=6,241):\n",
      "  With school mention:   5,212 (83.51%)\n",
      "    â””â”€ Top schools:       252 (4.04%)\n",
      "    â””â”€ Non-top schools:   4,960 (79.47%)\n",
      "\n",
      "ğŸ§ª Test Set (n=1,759):\n",
      "  With school mention:   1,495 (84.99%)\n",
      "    â””â”€ Top schools:       73 (4.15%)\n",
      "    â””â”€ Non-top schools:   1,422 (80.84%)\n",
      "\n",
      "ğŸ“ Top 10 Most Mentioned Elite Schools:\n",
      "  berkeley......................    66 mentions\n",
      "  uchicago......................    44 mentions\n",
      "  peking........................    43 mentions\n",
      "  ucla..........................    34 mentions\n",
      "  princeton.....................    23 mentions\n",
      "  dartmouth.....................    20 mentions\n",
      "  johns_hopkins.................    18 mentions\n",
      "  northwestern..................    15 mentions\n",
      "  michigan......................    14 mentions\n",
      "  upenn.........................    14 mentions\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== çµ±è¨ˆåˆ†æ ====================\n",
    "print(\"\\nğŸ“Š SCHOOL CLASSIFICATION STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è¨“ç·´é›†å­¸æ ¡çµ±è¨ˆ\n",
    "train_with_school = sum(1 for s in train_school_stats if s['has_school'])\n",
    "train_top_school = sum(1 for s in train_school_stats if s['is_top_school'])\n",
    "train_non_top = sum(1 for s in train_school_stats if s['school_category'] == 'non_top_school')\n",
    "\n",
    "print(f\"\\nğŸ“š Training Set (n={len(train_ds):,}):\")\n",
    "print(f\"  With school mention:   {train_with_school:,} ({train_with_school/len(train_ds)*100:.2f}%)\")\n",
    "print(f\"    â””â”€ Top schools:       {train_top_school:,} ({train_top_school/len(train_ds)*100:.2f}%)\")\n",
    "print(f\"    â””â”€ Non-top schools:   {train_non_top:,} ({train_non_top/len(train_ds)*100:.2f}%)\")\n",
    "\n",
    "# æ¸¬è©¦é›†å­¸æ ¡çµ±è¨ˆ\n",
    "test_with_school = sum(1 for s in test_school_stats if s['has_school'])\n",
    "test_top_school = sum(1 for s in test_school_stats if s['is_top_school'])\n",
    "test_non_top = sum(1 for s in test_school_stats if s['school_category'] == 'non_top_school')\n",
    "\n",
    "print(f\"\\nğŸ§ª Test Set (n={len(test_ds):,}):\")\n",
    "print(f\"  With school mention:   {test_with_school:,} ({test_with_school/len(test_ds)*100:.2f}%)\")\n",
    "print(f\"    â””â”€ Top schools:       {test_top_school:,} ({test_top_school/len(test_ds)*100:.2f}%)\")\n",
    "print(f\"    â””â”€ Non-top schools:   {test_non_top:,} ({test_non_top/len(test_ds)*100:.2f}%)\")\n",
    "\n",
    "# æœ€å¸¸è¦‹çš„ top schools\n",
    "all_matched = []\n",
    "for s in train_school_stats + test_school_stats:\n",
    "    all_matched.extend(s['matched_schools'])\n",
    "\n",
    "if all_matched:\n",
    "    top_schools_counter = Counter(all_matched)\n",
    "    print(f\"\\nğŸ“ Top 10 Most Mentioned Elite Schools:\")\n",
    "    for school, count in top_schools_counter.most_common(10):\n",
    "        print(f\"  {school:.<30} {count:>5} mentions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41e66a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ SAMPLE EXAMPLES\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Examples with Top Schools:\n",
      "\n",
      "Example 1:\n",
      "  School Category: top_school\n",
      "  Matched Schools: ['yale']\n",
      "  Resume snippet: ExperienceData, Research & Marketing Consultant,01/2019-01/2019Pfizerâ€“Columbus,OH,Https://rpinsights.com, https://rpmarketingco.com.Designing membership surveys and managing CRM databases for non-profit organization.Helping businesses with branding, ...\n",
      "\n",
      "Example 2:\n",
      "  School Category: top_school\n",
      "  Matched Schools: ['uchicago']\n",
      "  Resume snippet: QUALIFICATIONSâ€¢Â Â  Over two years' experience of data analysis\n",
      "at Loyola Chicago University; providing statistical analysis plan and\n",
      "generating report, tables, graphs;\n",
      "proficient in R and SAS.â€¢Â Â  Proficient in Microsoft Office, Word, Excel\n",
      "and Power P...\n",
      "\n",
      "Example 3:\n",
      "  School Category: top_school\n",
      "  Matched Schools: ['ucla']\n",
      "  Resume snippet: SummaryDedi100 Montgomery St. 10th Floorted Health 100 Montgomery St. 10th Floorre Administrator at improving team productivity, policies, clini100 Montgomery St. 10th Floorl processes, and performance improvement to maintain sustainability, and lowe...\n",
      "\n",
      "Example 4:\n",
      "  School Category: top_school\n",
      "  Matched Schools: ['dartmouth', 'michigan', 'unc']\n",
      "  Resume snippet: ProfileDedicated Epidemiologist/Data Manager with excellent technical, analytical and communication skills demonstrated by 17 years of experience.Experienced professional with strong leadership and relationship-building skills.\n",
      "SkillsSAS Statistical ...\n",
      "\n",
      "Example 5:\n",
      "  School Category: top_school\n",
      "  Matched Schools: ['harvard']\n",
      "  Resume snippet: ProfileA/E Business Operations leader with two decades of design, project and practice management experience with large multi-disciplinary design firms.\n",
      "Areas of ExpertiseProject /Program ManagementOperations ManagementChange ManagementRisk Managemen...\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== ç¤ºä¾‹å±•ç¤º ====================\n",
    "print(\"\\nğŸ“‹ SAMPLE EXAMPLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æ‰¾å‡ºæœ‰ top school çš„ç¯„ä¾‹\n",
    "print(\"\\nğŸ“ Examples with Top Schools:\\n\")\n",
    "school_examples_shown = 0\n",
    "for idx, (example, school_info) in enumerate(zip(train_ds, train_school_stats)):\n",
    "    if school_info['is_top_school'] and school_examples_shown < 5:\n",
    "        resume = example.get('resume_text', '')\n",
    "        print(f\"Example {school_examples_shown + 1}:\")\n",
    "        print(f\"  School Category: {school_info['school_category']}\")\n",
    "        print(f\"  Matched Schools: {school_info['matched_schools']}\")\n",
    "        print(f\"  Resume snippet: {resume[:250]}...\")\n",
    "        print()\n",
    "        school_examples_shown += 1\n",
    "    if school_examples_shown >= 5:\n",
    "        break\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f319865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¬ DETAILED VALIDATION\n",
      "============================================================\n",
      "\n",
      "ğŸ“ School Detection Validation:\n",
      "\n",
      "Sample matches with context:\n",
      "\n",
      "1. School: yale\n",
      "   Context: ...sophy (PhD):,Expected in-Yale University-New Haven,CTGPA:Status-Bachel...\n",
      "\n",
      "2. School: ucla\n",
      "   Context: ...y College, Glendale Community College, Northridge University, UCLA,...\n",
      "\n",
      "3. School: dartmouth\n",
      "   Context: ...project components.Dartmouth College-DATA MANAGER/EPIDEMIOLOGISTHa...\n",
      "\n",
      "4. School: michigan\n",
      "   Context: ...project components.Dartmouth College-DATA MANAGER/EPIDEMIOLOGISTHa...\n",
      "\n",
      "5. School: unc\n",
      "   Context: ...project components.Dartmouth College-DATA MANAGER/EPIDEMIOLOGISTHa...\n",
      "\n",
      "6. School: harvard\n",
      "   Context: ...cted in2021toHarvard Business School (HBS)-,GPA:Admitted to the co...\n",
      "\n",
      "7. School: berkeley\n",
      "   Context: ...ment,Expected in2019-Berkeley University of California-San Francisco,C...\n",
      "\n",
      "8. School: dartmouth\n",
      "   Context: ...s-section scan data.Dartmouth College-Product Engineering Intern,,-...\n",
      "\n",
      "9. School: yale\n",
      "   Context: ...sophy (PhD):,Expected in-Yale University-New Haven,CTGPA:Status-Bachel...\n",
      "\n",
      "10. School: berkeley\n",
      "   Context: ...ment,Expected in2019-Berkeley University of California-San Francisco,C...\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== è©³ç´°é©—è­‰åˆ†æ ====================\n",
    "print(\"\\nğŸ”¬ DETAILED VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# å­¸æ ¡åˆ†é¡é©—è­‰ - æŸ¥çœ‹ä¸€äº›å¯¦éš›åŒ¹é…\n",
    "print(\"\\nğŸ“ School Detection Validation:\\n\")\n",
    "school_with_context = []\n",
    "for idx, (example, school_info) in enumerate(zip(train_ds, train_school_stats)):\n",
    "    if school_info['is_top_school']:\n",
    "        resume = example.get('resume_text', '')\n",
    "        for school in school_info['matched_schools']:\n",
    "            # æ‰¾å‡ºå­¸æ ¡åç¨±åœ¨æ–‡æœ¬ä¸­çš„ä¸Šä¸‹æ–‡\n",
    "            text_lower = resume.lower()\n",
    "            for match in re.finditer(r'\\b\\w*(?:university|college|school|institute)\\w*\\b', text_lower):\n",
    "                context = resume[max(0, match.start()-30):min(len(resume), match.end()+30)]\n",
    "                if any(s.replace('_', ' ') in context.lower() for s in school_info['matched_schools']):\n",
    "                    school_with_context.append({\n",
    "                        'school': school,\n",
    "                        'context': context.strip()\n",
    "                    })\n",
    "                    break\n",
    "            if len(school_with_context) >= 15:\n",
    "                break\n",
    "    if len(school_with_context) >= 15:\n",
    "        break\n",
    "\n",
    "print(\"Sample matches with context:\")\n",
    "for i, item in enumerate(school_with_context[:10], 1):\n",
    "    print(f\"\\n{i}. School: {item['school']}\")\n",
    "    print(f\"   Context: ...{item['context']}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ce2b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Adding features to datasets...\n",
      "âœ… Features added successfully!\n",
      "\n",
      "ğŸ“Š Updated dataset columns:\n",
      "  ['resume_text', 'job_description_text', 'label', 'is_top_school', 'school_category']\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== å°‡ç‰¹å¾µåŠ å…¥è³‡æ–™é›† ====================\n",
    "print(\"\\nğŸ’¾ Adding features to datasets...\")\n",
    "\n",
    "# ç§»é™¤èˆŠçš„æ¬„ä½ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
    "cols_to_remove = ['has_gender_indicator', 'inferred_gender', 'male_count', 'female_count', \n",
    "                  'is_top_school', 'school_category', 'matched_schools']\n",
    "for col in cols_to_remove:\n",
    "    if col in train_ds.column_names:\n",
    "        train_ds = train_ds.remove_columns(col)\n",
    "    if col in test_ds.column_names:\n",
    "        test_ds = test_ds.remove_columns(col)\n",
    "\n",
    "# ç‚ºè¨“ç·´é›†æ·»åŠ ç‰¹å¾µ\n",
    "train_ds = train_ds.add_column('is_top_school', [s['is_top_school'] for s in train_school_stats])\n",
    "train_ds = train_ds.add_column('school_category', [s['school_category'] for s in train_school_stats])\n",
    "\n",
    "# ç‚ºæ¸¬è©¦é›†æ·»åŠ ç‰¹å¾µ\n",
    "test_ds = test_ds.add_column('is_top_school', [s['is_top_school'] for s in test_school_stats])\n",
    "test_ds = test_ds.add_column('school_category', [s['school_category'] for s in test_school_stats])\n",
    "\n",
    "print(\"âœ… Features added successfully!\")\n",
    "print(f\"\\nğŸ“Š Updated dataset columns:\")\n",
    "print(f\"  {list(train_ds.features.keys())}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "692684ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ¨ Data preparation complete!\n",
      "\n",
      "ğŸ“¦ Datasets ready for fairness analysis:\n",
      "  - train_ds: 6,241 examples with 5 features\n",
      "  - test_ds:  1,759 examples with 5 features\n"
     ]
    }
   ],
   "source": [
    "# ==================== ä¿å­˜è™•ç†å¾Œçš„è³‡æ–™ (å¯é¸) ====================\n",
    "# å¦‚æœéœ€è¦ä¿å­˜è™•ç†å¾Œçš„è³‡æ–™é›†ï¼Œå–æ¶ˆä¸‹æ–¹è¨»è§£\n",
    "\n",
    "# from datasets import DatasetDict\n",
    "# \n",
    "# dataset_dict = DatasetDict({\n",
    "#     'train': train_ds,\n",
    "#     'test': test_ds\n",
    "# })\n",
    "# \n",
    "# # ä¿å­˜åˆ°æœ¬åœ°\n",
    "# dataset_dict.save_to_disk('./processed_resume_dataset')\n",
    "# print(\"âœ… Dataset saved to ./processed_resume_dataset\")\n",
    "# \n",
    "# # æˆ–æ¨é€åˆ° Hugging Face Hub (éœ€è¦å…ˆç™»å…¥)\n",
    "# # dataset_dict.push_to_hub(\"your-username/resume-job-fit-with-fairness-features\")\n",
    "\n",
    "print(\"\\nâœ¨ Data preparation complete!\")\n",
    "print(f\"\\nğŸ“¦ Datasets ready for fairness analysis:\")\n",
    "print(f\"  - train_ds: {len(train_ds):,} examples with {len(train_ds.column_names)} features\")\n",
    "print(f\"  - test_ds:  {len(test_ds):,} examples with {len(test_ds.column_names)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29bc3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Inspecting actual data format...\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ First example structure:\n",
      "Keys: ['resume_text', 'job_description_text', 'label']\n",
      "\n",
      "\n",
      "============================================================\n",
      "Example 1:\n",
      "============================================================\n",
      "\n",
      "[resume_text]:\n",
      "SummaryHighly motivated Sales Associate with extensive customer service and sales experience. Outgoing sales professional with track record of driving increased sales, improving buying experience and elevating company profile with target market.\n",
      "Highlights-Soft Skills: Public Speaking, Public Relati...\n",
      "\n",
      "[job_description_text]:\n",
      "Net2Source Inc. is an award-winning total workforce solutions company recognized by Staffing Industry Analysts for our accelerated growth of 300% in the last 3 years with over 5500+ employees globally, with over 30+ locations in the US and global operations in 32 countries. We believe in providing s...\n",
      "\n",
      "[label]:\n",
      "No Fit\n",
      "\n",
      "\n",
      "============================================================\n",
      "Example 2:\n",
      "============================================================\n",
      "\n",
      "[resume_text]:\n",
      "Professional SummaryCurrently working with Caterpillar as an contract employee Active in several NPI and CPI projects Provide technical for CAT facilities worldwide 24-hours a day Willing to travel to meet job requirements Familiar with Power Distribution Systems, NETA, NFPA 70E, and OHSA electrical...\n",
      "\n",
      "[job_description_text]:\n",
      "At Salas OBrien we tell our clients that were engineered for impact. This passion for making a difference applies just as much to our team as it does to our projects. Thats why were committed to living our values every day: inspiring, achieving, and connecting as shared owners of our success with a ...\n",
      "\n",
      "[label]:\n",
      "No Fit\n",
      "\n",
      "\n",
      "============================================================\n",
      "Example 3:\n",
      "============================================================\n",
      "\n",
      "[resume_text]:\n",
      "SummaryI started my construction career in June of 2017 in Jacksonville, Florida as an Electrical Apprentice working full time and attending the Jacksonville Electrical Training Alliance. this experience provided invaluable insight into electrical systems work and the related theory. Knowledgeable l...\n",
      "\n",
      "[job_description_text]:\n",
      "Schweitzer Engineering Laboratories (SEL) Infrastructure Defense Division seeks a talented individual for a cybersecurity focused (Lead) Software Engineer position. The work we perform is some of the most fascinating, challenging, and rewarding that can be found in the power engineering community.\n",
      "L...\n",
      "\n",
      "[label]:\n",
      "No Fit\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== æª¢æŸ¥è³‡æ–™æ ¼å¼ ====================\n",
    "print(\"ğŸ” Inspecting actual data format...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æŸ¥çœ‹ç¬¬ä¸€ç­†è³‡æ–™çš„çµæ§‹\n",
    "print(\"ğŸ“‹ First example structure:\")\n",
    "print(f\"Keys: {list(train_ds[0].keys())}\\n\")\n",
    "\n",
    "# æŸ¥çœ‹å‰3ç­†å±¥æ­·çš„å®Œæ•´å…§å®¹\n",
    "for i in range(min(3, len(train_ds))):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    example = train_ds[i]\n",
    "    \n",
    "    # é¡¯ç¤ºæ‰€æœ‰æ¬„ä½\n",
    "    for key, value in example.items():\n",
    "        if isinstance(value, str):\n",
    "            preview = value[:300] + \"...\" if len(value) > 300 else value\n",
    "            print(f\"\\n[{key}]:\")\n",
    "            print(f\"{preview}\")\n",
    "        else:\n",
    "            print(f\"\\n[{key}]: {value}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f8cf3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saving processed datasets...\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27307417ed7d4ed3b3439f2cfd3d9402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5844e665fb614e3da00688469775618b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1759 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset saved to: ./processed_resume_dataset\n",
      "\n",
      "ğŸ“Š Saved Dataset Information:\n",
      "  ğŸ“ Location: ./processed_resume_dataset\n",
      "  ğŸ“ Train: 6,241 examples\n",
      "  ğŸ§ª Test:  1,759 examples\n",
      "  ğŸ·ï¸  Features: ['resume_text', 'job_description_text', 'label', 'is_top_school', 'school_category']\n",
      "\n",
      "ğŸ¯ School Classification Features:\n",
      "  - is_top_school: Boolean (æ˜¯å¦ç‚ºé ‚å°–å­¸æ ¡)\n",
      "  - school_category: String (top_school/non_top_school/no_school_mentioned)\n",
      "\n",
      "============================================================\n",
      "âœ¨ All done! Dataset is ready for use.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== ä¿å­˜è™•ç†å¾Œçš„è³‡æ–™é›† ====================\n",
    "from datasets import DatasetDict\n",
    "import os\n",
    "\n",
    "print(\"ğŸ’¾ Saving processed datasets...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# å»ºç«‹è¼¸å‡ºç›®éŒ„\n",
    "output_dir = './processed_resume_dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# å»ºç«‹ DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'test': test_ds\n",
    "})\n",
    "\n",
    "# ä¿å­˜åˆ°æœ¬åœ°\n",
    "dataset_dict.save_to_disk(output_dir)\n",
    "print(f\"âœ… Dataset saved to: {output_dir}\")\n",
    "\n",
    "# é¡¯ç¤ºè³‡æ–™é›†è³‡è¨Š\n",
    "print(f\"\\nğŸ“Š Saved Dataset Information:\")\n",
    "print(f\"  ğŸ“ Location: {output_dir}\")\n",
    "print(f\"  ğŸ“ Train: {len(train_ds):,} examples\")\n",
    "print(f\"  ğŸ§ª Test:  {len(test_ds):,} examples\")\n",
    "print(f\"  ğŸ·ï¸  Features: {list(train_ds.features.keys())}\")\n",
    "print(f\"\\nğŸ¯ School Classification Features:\")\n",
    "print(f\"  - is_top_school: Boolean (æ˜¯å¦ç‚ºé ‚å°–å­¸æ ¡)\")\n",
    "print(f\"  - school_category: String (top_school/non_top_school/no_school_mentioned)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ¨ All done! Dataset is ready for use.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f9f03",
   "metadata": {},
   "source": [
    "## ğŸ“š å¦‚ä½•ä½¿ç”¨ä¿å­˜çš„è³‡æ–™é›†\n",
    "\n",
    "### è¼‰å…¥è³‡æ–™é›†\n",
    "\n",
    "```python\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# è¼‰å…¥è³‡æ–™é›†\n",
    "dataset = load_from_disk('./processed_resume_dataset')\n",
    "\n",
    "# è¨ªå•è¨“ç·´é›†å’Œæ¸¬è©¦é›†\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "```\n",
    "\n",
    "### è³‡æ–™é›†æ¬„ä½èªªæ˜\n",
    "\n",
    "| æ¬„ä½åç¨± | é¡å‹ | èªªæ˜ |\n",
    "|---------|------|------|\n",
    "| `resume_text` | String | å±¥æ­·æ–‡æœ¬å…§å®¹ |\n",
    "| `job_description_text` | String | è·ä½æè¿°æ–‡æœ¬ |\n",
    "| `label` | String | åŒ¹é…æ¨™ç±¤ (Fit/No Fit) |\n",
    "| `is_top_school` | Boolean | æ˜¯å¦æåŠé ‚å°–å­¸æ ¡ |\n",
    "| `school_category` | String | å­¸æ ¡é¡åˆ¥ (top_school/non_top_school/no_school_mentioned) |\n",
    "\n",
    "### ç¯„ä¾‹ä½¿ç”¨\n",
    "\n",
    "```python\n",
    "# æŸ¥çœ‹ç¬¬ä¸€ç­†è³‡æ–™\n",
    "print(train_data[0])\n",
    "\n",
    "# ç¯©é¸åŒ…å«é ‚å°–å­¸æ ¡çš„å±¥æ­·\n",
    "top_school_resumes = train_data.filter(lambda x: x['is_top_school'])\n",
    "print(f\"Top school resumes: {len(top_school_resumes)}\")\n",
    "\n",
    "# æŒ‰å­¸æ ¡é¡åˆ¥åˆ†çµ„\n",
    "from collections import Counter\n",
    "school_dist = Counter(train_data['school_category'])\n",
    "print(school_dist)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73f665ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Verifying saved dataset...\n",
      "============================================================\n",
      "\n",
      "âœ… Dataset loaded successfully!\n",
      "\n",
      "ğŸ“Š Dataset Structure:\n",
      "  Splits: ['train', 'test']\n",
      "  Train size: 6,241\n",
      "  Test size: 1,759\n",
      "\n",
      "ğŸ·ï¸  Features:\n",
      "  - resume_text: Value('string')\n",
      "  - job_description_text: Value('string')\n",
      "  - label: Value('string')\n",
      "  - is_top_school: Value('bool')\n",
      "  - school_category: Value('string')\n",
      "\n",
      "ğŸ“ Sample Data (First Example):\n",
      "  Resume (first 150 chars): SummaryHighly motivated Sales Associate with extensive customer service and sales experience. Outgoing sales professional with track record of driving...\n",
      "  Label: No Fit\n",
      "  Is Top School: False\n",
      "  School Category: non_top_school\n",
      "\n",
      "ğŸ“ˆ School Distribution:\n",
      "  non_top_school...........  4960 (79.47%)\n",
      "  top_school...............   252 ( 4.04%)\n",
      "  no_school_mentioned......  1029 (16.49%)\n",
      "\n",
      "============================================================\n",
      "âœ… Verification complete - Dataset is ready to use!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== é©—è­‰è³‡æ–™é›†è¼‰å…¥ ====================\n",
    "print(\"ğŸ” Verifying saved dataset...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# é‡æ–°è¼‰å…¥è³‡æ–™é›†é€²è¡Œé©—è­‰\n",
    "loaded_dataset = load_from_disk('./processed_resume_dataset')\n",
    "\n",
    "print(f\"\\nâœ… Dataset loaded successfully!\")\n",
    "print(f\"\\nğŸ“Š Dataset Structure:\")\n",
    "print(f\"  Splits: {list(loaded_dataset.keys())}\")\n",
    "print(f\"  Train size: {len(loaded_dataset['train']):,}\")\n",
    "print(f\"  Test size: {len(loaded_dataset['test']):,}\")\n",
    "\n",
    "print(f\"\\nğŸ·ï¸  Features:\")\n",
    "for feature_name, feature_type in loaded_dataset['train'].features.items():\n",
    "    print(f\"  - {feature_name}: {feature_type}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Sample Data (First Example):\")\n",
    "sample = loaded_dataset['train'][0]\n",
    "print(f\"  Resume (first 150 chars): {sample['resume_text'][:150]}...\")\n",
    "print(f\"  Label: {sample['label']}\")\n",
    "print(f\"  Is Top School: {sample['is_top_school']}\")\n",
    "print(f\"  School Category: {sample['school_category']}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ School Distribution:\")\n",
    "from collections import Counter\n",
    "train_schools = Counter(loaded_dataset['train']['school_category'])\n",
    "for category, count in train_schools.items():\n",
    "    pct = count / len(loaded_dataset['train']) * 100\n",
    "    print(f\"  {category:.<25} {count:>5} ({pct:>5.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Verification complete - Dataset is ready to use!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
